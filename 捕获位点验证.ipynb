{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01643c66-adcf-4d15-a6bc-c395f01a6ff6",
   "metadata": {},
   "source": [
    "## 原始方法 是否和  CIGAR(M/=/X) 解析的坐标一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c2167e-766f-4ad7-bfaf-c195df7fa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAM_FILE = \"/data/work/human_brain/710_68_1_humanbrain_251209_NB.duplicates.directional.bam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9e7937-1693-4dc1-9620-479aa825227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "import gffutils\n",
    "import matplotlib.pyplot as plt\n",
    "from intervaltree import IntervalTree\n",
    "\n",
    "def get_precise_capture_site(read):\n",
    "    # <--- 新增：CIGAR 字符串解析捕获位点\n",
    "    \"\"\"\n",
    "    根据 CIGAR 字符串解析出最后一个真正匹配 (M/=/X) 的基因组坐标\n",
    "    返回该位点所在的 M/=/X 块的长度 (m_length)\n",
    "    \"\"\"\n",
    "    # 获取 CIGAR 元组，如果为空则返回默认值\n",
    "    cigars = read.cigartuples\n",
    "    if not cigars:\n",
    "        return (read.reference_start, 0)\n",
    "    \n",
    "    if not read.is_reverse:\n",
    "        # 正向链 (+): 寻找最后一个匹配碱基的末端坐标\n",
    "        curr_ref_pos = read.reference_start\n",
    "        last_match_end = read.reference_start\n",
    "        last_m_len = 0\n",
    "        if cigars:\n",
    "            for op, length in cigars:\n",
    "                if op in (0, 2, 7, 8): # M, D, =, X (消耗参考基因组坐标)\n",
    "                    curr_ref_pos += length\n",
    "                    if op != 2: # 只有 M, =, X 是真实匹配，D 是缺失\n",
    "                        last_match_end = curr_ref_pos\n",
    "                        last_m_len = length\n",
    "                elif op == 3: # N (跨越内含子，消耗坐标)\n",
    "                    curr_ref_pos += length\n",
    "        return last_match_end, last_m_len\n",
    "    else:\n",
    "        # 反向链 (-): 寻找第一个匹配碱基的起始坐标\n",
    "        curr_ref_pos = read.reference_start\n",
    "        first_m_len = 0\n",
    "        if cigars:\n",
    "            for op, length in cigars:\n",
    "                if op in (0, 7, 8): # 找到第一个真正的匹配块 (M, =, X)\n",
    "                    first_m_len = length\n",
    "                    return curr_ref_pos, first_m_len\n",
    "                if op in (2, 3): # D, N 消耗坐标\n",
    "                    curr_ref_pos += length\n",
    "        return read.reference_start,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5654e96e-7642-4d2e-96f8-b0b152e243ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def verify_all_reads_capture_logic(bam_path):\n",
    "    \"\"\"\n",
    "    对比过滤后的 Primary Aligned Reads：\n",
    "    原始方法 vs CIGAR 精确解析\n",
    "    \"\"\"\n",
    "    bf = pysam.AlignmentFile(bam_path, \"rb\")\n",
    "    \n",
    "    # 为了节省内存：\n",
    "    # 1. 差异列表：只存储 offset != 0 的 read 信息\n",
    "    diff_data = []\n",
    "    # 2. 计数器：记录总体情况\n",
    "    stats = {\n",
    "        \"total_processed\": 0,\n",
    "        \"primary_count\": 0,\n",
    "        \"consistent_count\": 0,\n",
    "        \"diff_count\": 0\n",
    "    }\n",
    "\n",
    "    print(f\"--- 开始全量扫描 BAM: {bam_path} ---\")\n",
    "\n",
    "    for read in bf.fetch(until_eof=True):\n",
    "        stats[\"total_processed\"] += 1\n",
    "        \n",
    "        # 核心过滤逻辑\n",
    "        if read.is_unmapped or read.is_secondary or read.is_supplementary:\n",
    "            continue\n",
    "        \n",
    "        stats[\"primary_count\"] += 1\n",
    "        \n",
    "        # 1. 原始方法坐标\n",
    "        if not read.is_reverse:  →找到原因了！！！\n",
    "            raw_site = read.reference_end\n",
    "        else:\n",
    "            raw_site = read.reference_start\n",
    "        \n",
    "        # 2. CIGAR 精确解析 (使用新定义的函数)\n",
    "        precise_site, m_len = get_precise_capture_site(read)\n",
    "        \n",
    "        # 3. 计算偏移\n",
    "        offset = precise_site - raw_site\n",
    "        \n",
    "        if offset == 0:\n",
    "            stats[\"consistent_count\"] += 1\n",
    "        else:\n",
    "            stats[\"diff_count\"] += 1\n",
    "            # 只有在不一致时才记录详细信息，极大地节省内存\n",
    "            diff_data.append({\n",
    "                'read_name': read.query_name,\n",
    "                'strand': '-' if read.is_reverse else '+',\n",
    "                'cigar': read.cigarstring,\n",
    "                'raw_site': raw_site,\n",
    "                'precise_site': precise_site,\n",
    "                'offset': offset,\n",
    "                'terminal_m_len': m_len\n",
    "            })\n",
    "\n",
    "        # 每 100 万条打印一次进度\n",
    "        if stats[\"primary_count\"] % 1000000 == 0:\n",
    "            print(f\"进度：已处理 {stats['primary_count'] // 1000000}M 条 Primary Reads...\")\n",
    "\n",
    "    bf.close()\n",
    "\n",
    "    # 转换为 DataFrame 仅包含有差异的部分\n",
    "    df_diff = pd.DataFrame(diff_data)\n",
    "    \n",
    "    # --- 生成最终报告 ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"全量验证最终报告\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"BAM 总 Reads 数:    {stats['total_processed']}\")\n",
    "    print(f\"通过过滤的 Primary:  {stats['primary_count']}\")\n",
    "    print(f\"坐标完全一致:       {stats['consistent_count']}\")\n",
    "    print(f\"坐标存在差异:       {stats['diff_count']}\")\n",
    "    \n",
    "    if stats[\"primary_count\"] > 0:\n",
    "        error_rate = (stats[\"diff_count\"] / stats[\"primary_count\"]) * 100\n",
    "        print(f\"受影响 Read 占比:   {error_rate:.2f}%\")\n",
    "    \n",
    "    if not df_diff.empty:\n",
    "        print(\"\\n--- 偏移量 (Offset) 最大/最小统计 ---\")\n",
    "        print(f\"最大正向偏移: {df_diff['offset'].max()} bp\")\n",
    "        print(f\"最大负向偏移: {df_diff['offset'].min()} bp\")\n",
    "        \n",
    "        # 可视化差异分布\n",
    "        plot_offset_distribution(df_diff)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return df_diff\n",
    "\n",
    "def plot_offset_distribution(df_diff):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df_diff['offset'], bins=100, color='salmon', edgecolor='black', alpha=0.7)\n",
    "    plt.yscale('log') # 使用对数刻度，因为小的偏移可能非常多，大的偏移很少\n",
    "    plt.title('Distribution of Coordinate Offsets (Precise - Raw)')\n",
    "    plt.xlabel('Offset (bp)')\n",
    "    plt.ylabel('Read Count (Log Scale)')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c55e036-5248-4df2-9287-7ad7b0c16e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 开始全量扫描 BAM: /data/work/human_brain/710_68_1_humanbrain_251209_NB.duplicates.directional.bam ---\n",
      "进度：已处理 1M 条 Primary Reads...\n",
      "进度：已处理 2M 条 Primary Reads...\n",
      "进度：已处理 3M 条 Primary Reads...\n",
      "进度：已处理 4M 条 Primary Reads...\n",
      "进度：已处理 5M 条 Primary Reads...\n",
      "进度：已处理 6M 条 Primary Reads...\n",
      "进度：已处理 7M 条 Primary Reads...\n",
      "\n",
      "==================================================\n",
      "全量验证最终报告\n",
      "--------------------------------------------------\n",
      "BAM 总 Reads 数:    7662144\n",
      "通过过滤的 Primary:  7662144\n",
      "坐标完全一致:       7662144\n",
      "坐标存在差异:       0\n",
      "受影响 Read 占比:   0.00%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "df_verify = verify_all_reads_capture_logic(BAM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36320209-7c58-47a1-8688-cb578f19af22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cf243-6b1b-4fd5-b6cf-113456667997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwhjf",
   "language": "python",
   "name": "fwhjf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
